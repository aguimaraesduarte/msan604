Fstar_b2 <- MSR_b2 / MSEf
Flim_b2 <- qf(p=0.975, df1=1 , df2=dff)
MSR_b2
Fstar_b2
Flim_b2
lm2 <- lm(data=cakes, Y ~ X2 + I(X2^2))
summary(lm2)
pr <- 3
dfr <- n-pr
SSEr <- tail(car::Anova(lm2)$"Sum Sq", 1)
Fstar_b1b2b5 <- ((SSEr - SSEf)/(dfr-dff)) / (SSEf/dff)
Flim_b1b2b5 <- qf(p=0.975, df1=3 , df2=dff)
SSEr
dfr
n-p-3
n-pf-3
n-(pf-3)
Fstar_b1b2b5 <- ((SSEr - SSEf)/(dfr-dff)) / (SSEf/dff)
Fstar_b1b2b5
Flim_b1b2b5 <- qf(p=0.975, df1=3 , df2=dff)
Flim_b1b2b5
dfr-dff
landrent <- alr4::landrent
rm(list=ls())
cat("\014")
landrent <- alr4::landrent
lm1 <- lm(data=landrent, Y ~ X1 + X2 + X3 + X4)
summary(lm1)
plot(landrent)
plot(landrent$Y~landrent$X2)
summary(lm(landrent$Y~landrent$X2))
plot(landrent$Y~landrent$X1)
plot(landrent$Y~landrent$X3)
plot(landrent$Y~landrent$X4)
plot(landrent$Y~landrent$X3)
plot(landrent$Y~log(landrent$X3))
summary(lm(landrent$Y~log(landrent$X3)))
summary(lm(landrent$Y~landrent$X1+log(landrent$X3)))
summary(lm(landrent$Y~landrent$X1+landrent$X2+log(landrent$X3)))
pairs(landrent)
cor(landrent)
plot(landrent)
pairs(landrent)
summary(lm(data=landrent, Y ~ X1 + X2 + X3))
summary(lm(data=landrent, Y ~ X1 + X2 + X4))
lm_f <- lm(data=landrent, Y ~ X1 + X2)
summary(lm_f)
scatterplot(landrent)
scatterplot(landrent$X1, landrent$Y)
scatterplot(landrent$Y~landrent$X1)
scatterplot(landrent$Y~landrent$X1+landrent$X2)
residualPlot(lm_f)
plot(lm_f$residuals, xlab="Sequence", ylab="Residuals",
main="Sequence Plot")
par(mfrow=c(1,2))
plot(stdres(lm_f), xlab="", ylab="",
main="Standardized Residual Plot")
library(MASS)
detach(MASS)
detach("MASS")
detach("package:MASS", unload=TRUE)
par(mfrow=c(1,2))
plot(MASS::stdres(lm_f), xlab="", ylab="",
main="Standardized Residual Plot")
abline(h=0)
plot(MASS::studres(lm_f), xlab="", ylab="",
main="Studentized Residual Plot")
abline(h=0)
par(mfrow=c(1,1))
residplot <- function(fit, nbreaks=10) {
z <- rstudent(fit)
hist(z, breaks=nbreaks, freq=FALSE,
xlab="Studentized Residual",
main="Distribution of Errors")
rug(jitter(z), col="brown")
curve(dnorm(x, mean=mean(z), sd=sd(z)),
add=TRUE, col="blue", lwd=2)
lines(density(z)$x, density(z)$y,
col="red", lwd=2, lty=2)
legend("topright",
legend = c( "Normal Curve", "Kernel Density Curve"),
lty=1:2, col=c("blue","red"), cex=.7)
}
residplot(lm_f)
shapiro.test(lm_UN$residuals)
shapiro.test(lm_f$residuals)
qqPlot(residuals(lm_f), main="landrent: Normal QQ-Plot", xlab="", ylab="")
residualPlot(lm_f)
plot(lm_f$residuals, xlab="Sequence", ylab="Residuals",
main="Sequence Plot")
par(mfrow=c(1,2))
plot(MASS::stdres(lm_f), xlab="", ylab="",
main="Standardized Residual Plot")
abline(h=0)
plot(MASS::studres(lm_f), xlab="", ylab="",
main="Studentized Residual Plot")
abline(h=0)
plot(landrent)
par(mfrow=c(1,2))
plot(MASS::stdres(lm_f), xlab="Standardized Residual", ylab="Sequence",
main="Standardized Residual Plot")
abline(h=0)
plot(MASS::studres(lm_f), xlab="Studentized Residual", ylab="Sequence",
main="Studentized Residual Plot")
abline(h=0)
par(mfrow=c(1,1))
residplot <- function(fit, nbreaks=10) {
z <- rstudent(fit)
hist(z, breaks=nbreaks, freq=FALSE,
xlab="Studentized Residual",
main="Distribution of Errors")
rug(jitter(z), col="brown")
curve(dnorm(x, mean=mean(z), sd=sd(z)),
add=TRUE, col="blue", lwd=2)
lines(density(z)$x, density(z)$y,
col="red", lwd=2, lty=2)
legend("topright",
legend = c( "Normal Curve", "Kernel Density Curve"),
lty=1:2, col=c("blue","red"), cex=.7)
}
residplot(lm_f)
plot(lm_f$residuals, xlab="Sequence", ylab="Residuals",
main="Sequence Plot")
par(mfrow=c(1,2))
plot(MASS::stdres(lm_f), xlab="Standardized Residual", ylab="Sequence",
main="Standardized Residual Plot")
abline(h=0)
plot(MASS::studres(lm_f), xlab="Studentized Residual", ylab="Sequence",
main="Studentized Residual Plot")
abline(h=0)
par(mfrow=c(1,2))
plot(MASS::stdres(lm_f), xlab="Sequence", ylab="Standardized Residual",
main="Standardized Residual Plot")
abline(h=0)
plot(MASS::studres(lm_f), xlab="Sequence", ylab="Studentized Residual",
main="Studentized Residual Plot")
abline(h=0)
landrent
bptest(lm_f)
lm_test::bptest(lm_f)
lmtest::bptest(lm_f)
residualPlot(lm_f)
par(mfrow=c(1,1))
residualPlot(lm_f)
landrent$X1
median(landrent$X1)
median(landrent$X2)
landrent
landrent$Group <- factor(apply(landrent, 1, function(x){
if(x[1]<=44.56){return(0)} else{return(1)}}))
landrent
leveneTest(data=landrent, Y ~ Group, center=median)
lm3 <- lm(data=landrent, Y ~ X1 + X2 + X3)
summary(lm3)
lm4 <- lm(data=landrent, Y ~ X1 + X2 + X4)
summary(lm3)
summary(lm_f)
qqPlot(residuals(lm_f), main="landrent: Normal QQ-Plot", xlab="", ylab="")
residplot(lm_f)
leveneTest(data=landrent, Y ~ Group, center=median)
shapiro.test(lm_f$residuals)
lm3 <- lm(data=landrent, Y ~ X1 + X2 + X3)
summary(lm3)
summary(lm_f)
summary(lm3)
lm4 <- lm(data=landrent, Y ~ X1 + X2 + X4)
summary(lm3)
summary(lm34
)
summary(lm4)
summary(lm1)
summary(lm(data=landrent, Y ~ X1 + X3)
)
rm(list=ls())
cat("\014")
rateprof <- alr4::Rateprof
detach("package:car", unload=TRUE)
transaction <- Transact
transaction <- alr4::Transact
normal <- rnorm(5000, 0, 1) + c(1, 0, 2, 0, 1)
plot(normal)
shapiro.test(normal)
normal <- rnorm(5000, 0, 1) + c(1, 0, 2, 0, 1)
shapiro.test(normal)
non_normal <- runif(10)
non_normal
dist(non_normal)
hist(non_normal)
shapiro.test(non_normal)
non_normal <- runif(10)
shapiro.test(non_normal)
hist(non_normal)
non_normal <- replicate(1000, shapiro.test(runif(10))$p.value)
rowMeans(non_normal<0.05)
non_normal<0.05
sum(non_normal<0.05)
sum(non_normal<0.05)/1000
non_normal <- replicate(5000, shapiro.test(runif(10))$p.value)
sum(non_normal<0.05)/1000
sum(non_normal<0.05)/5000
non_normal <- replicate(5000, shapiro.test(runif(10))$p.value)
sum(non_normal<0.05)/length(non_normal)
normal <- rnorm(5000, 0, 1) + runif(5000, 1, 2)
normal <- replicate(rnorm(5000, 0, 1))# + runif(5000, 1, 2)
normal <- replicate(5000, rnorm(5000, 0, 1))# + runif(5000, 1, 2)
normal <- replicate(5000, shapiro.test(rnorm(5000, 0, 1))$p.value)# + runif(5000, 1, 2)
sum(normal<0.05)/length(normal)
sum(non_normal<0.05)/length(non_normal) * 100
sum(normal<0.05)/length(normal) * 100
sum(non_normal>0.05)/length(non_normal) * 100 # percent of times non-normal data is considered normal
sum(normal<0.05)/length(normal) * 100 # percent of times normal data is considered non-normal
install.packages("leaps")
install.packages("xlsx")
install.packages("rJava")
install.packages("xlsx")
library(xlsx)
library(rJava)
install.packages("rJava")
library(xlsx)
library(rJava)
Sys.getenv("JAVA_HOME")
install.packages("QuantPsyc")
install.packages('lawstat')
library(lawstat) # levene.test and runs.test need this
par(mfrow=c(2,1))
plot(BJsales)
BJ2 <- diff(diff(BJsales))
plot(BJ2)
# Fit the ARMA(1,2) model and extract the residuals
m <- arima(BJ2, order = c(1,0,2))
e <- m$residuals # residuals
r <- e/sqrt(m$sigma2) # standardized residuals
par(mfrow=c(2,1))
plot(e, main="Residuals vs t", ylab="")
abline(h=0, col="red")
plot(r, main="Standardized Residuals vs t", ylab="")
abline(h=0, col="red")
# test whether residuals have zero mean
t.test(e)
# test for heteroscedasticity
par(mfrow=c(1,1))
plot(e, main="Residuals vs t", ylab="")
abline(v=c(37,74,111), lwd=3, col="red")
group <- c(rep(1,37),rep(2,37),rep(3,37),rep(4,37))
levene.test(e,group) #Levene
bartlett.test(e,group) #Bartlett
# test for uncorrelatedness / randomness
tsdiag(m) #ACF and Ljung-Box test all in one!
runs.test(e) #Runs test for randomness
# test for normality
par(mfrow=c(1,1))
qqnorm(e, main="QQ-plot of Residuals")
qqline(e)
shapiro.test(e) #SW test
#######################
## ACF-PACF Examples ##
#######################
# MA(1) with n = 200
par(mfcol=c(3,1))
data.sim <- arima.sim(n = 200, list(ma = c(0.7)), sd = sqrt(1))
plot(data.sim, main="Simulated Data from an MA(1) Process")
acf(data.sim, main = "")
pacf(data.sim, main = "")
# or: acf(data.sim, type="partial")
# MA(1) with n = 1000
par(mfcol=c(3,1))
data.sim <- arima.sim(n = 1000, list(ma = c(0.7)), sd = sqrt(1))
plot(data.sim, main="Simulated Data from an MA(1) Process")
acf(data.sim, main = "")
pacf(data.sim, main = "")
# MA(2) with n = 200
par(mfcol=c(3,1))
data.sim <- arima.sim(n = 200, list(ma = c(0.7,-1)), sd = sqrt(1))
plot(data.sim, main="Simulated Data from an MA(2) Process")
acf(data.sim, main = "")
pacf(data.sim, main = "")
# MA(3) with n = 200
par(mfcol=c(3,1))
data.sim <- arima.sim(n = 200, list(ma = c(1,1,1)), sd = sqrt(1))
plot(data.sim, main="Simulated Data from an MA(3) Process")
acf(data.sim, main = "")
pacf(data.sim, main = "")
# AR(1) with n = 200
par(mfcol=c(3,1))
data.sim <- arima.sim(n = 200, list(ar = c(0.7)), sd = sqrt(1))
plot(data.sim, main="Simulated Data from an AR(1) Process")
acf(data.sim, main = "")
pacf(data.sim, main = "")
# AR(1) with n = 1000
par(mfcol=c(3,1))
data.sim <- arima.sim(n = 1000, list(ar = c(0.7)), sd = sqrt(1))
plot(data.sim, main="Simulated Data from an AR(1) Process")
acf(data.sim, main = "")
pacf(data.sim, main = "")
# AR(2) with n = 200
par(mfcol=c(3,1))
data.sim <- arima.sim(n =200, list(ar = c(-0.7, 0.1)), sd = sqrt(1))
plot(data.sim, main="Simulated Data from an AR(2) Process")
acf(data.sim, main = "")
pacf(data.sim, main = "")
# AR(4) with n = 200
par(mfcol=c(3,1))
data.sim <- arima.sim(n = 200, list(ar = c(0.7, 0.1, -0.2, 0.1)), sd = sqrt(1))
plot(data.sim, main="Simulated Data from an AR(4) Process")
acf(data.sim, main = "")
pacf(data.sim, main = "")
# ARMA(1,1) with n = 200
par(mfcol=c(3,1))
data.sim <- arima.sim(n = 200, list(ar=c(0.5) , ma = c(1)), sd = sqrt(1))
plot(data.sim, main="Simulated Data from an ARMA(1,1) Process")
acf(data.sim, main = "")
pacf(data.sim, main = "")
# ARMA(2,1) with n = 200
par(mfcol=c(3,1))
data.sim <- arima.sim(n = 200, list(ar=c(0.3,0.65) , ma = c(-0.5)), sd = sqrt(1))
plot(data.sim, main="Simulated Data from an ARMA(2,1) Process")
acf(data.sim, main = "")
pacf(data.sim, main = "")
#ARMA Fitting Example
#Use the BJsales data. Note that we have to assume the underlying time series is stationary,
#which this clearly not (check this:)
par(mfrow=c(2,1))
plot(BJsales)
#Instead we'll use the twice-differenced version of this time series. More discussion of the
#idea behind this differencing to come.
BJ2 <- diff(diff(BJsales))
plot(BJ2)
#Step 1 in the Box-Jenkins process is "Identification" (i.e., order identification).
#We will use ACF and PACF plots to help us decide what p and q are
acf(BJ2)
pacf(BJ2)
acf(BJ2, type="partial")
pacf(BJ2)
acf(BJ2)
pacf(BJ2)
fit.ar <- arima(BJ2, order=c(3,0,0)) #AR(3)
fit.ar
fit.ma <- arima(BJ2, order=c(0,0,1)) #MA(1)
fit.ma
fit.arma <- arima(BJ2, order=c(3,0,1)) #ARMA(3,1)
fit.arma
anova(fit.ma, fit.arma)
fitls.ar <- arima(BJ2, order=c(3,0,0), method="CSS") #AR(3)
fitls.ar
fitls.ma <- arima(BJ2, order=c(0,0,1), method="CSS") #MA(1)
fitls.ma
fitls.arma <- arima(BJ2, order=c(3,0,1), method="CSS") #ARMA(3,1)
fitls.arma
#We can fit any number of models of different orders and use the output information to select
#the model with the best fit.
m1<-arima(BJ2,order=c(1,0,0))
m2<-arima(BJ2,order=c(2,0,0))
m3<-arima(BJ2,order=c(3,0,0))
m4<-arima(BJ2,order=c(4,0,0))
m5<-arima(BJ2,order=c(0,0,1))
m6<-arima(BJ2,order=c(0,0,2))
m7<-arima(BJ2,order=c(1,0,1))
m8<-arima(BJ2,order=c(2,0,1))
m9<-arima(BJ2,order=c(3,0,1))
m10<-arima(BJ2,order=c(4,0,1))
m11<-arima(BJ2,order=c(1,0,2))
m12<-arima(BJ2,order=c(2,0,2))
m13<-arima(BJ2,order=c(3,0,2))
m14<-arima(BJ2,order=c(4,0,2))
sigma2<-c(m1$sigma2,m2$sigma2,m3$sigma2,m4$sigma2,m5$sigma2,m6$sigma2,m7$sigma2,m8$sigma2,m9$sigma2,m10$sigma2,m11$sigma2,m12$sigma2,m13$sigma2,m14$sigma2)
loglik<-c(m1$loglik,m2$loglik,m3$loglik,m4$loglik,m5$loglik,m6$loglik,m7$loglik,m8$loglik,m9$loglik,m10$loglik,m11$loglik,m12$loglik,m13$loglik,m14$loglik)
AIC<-c(m1$aic,m2$aic,m3$aic,m4$aic,m5$aic,m6$aic,m7$aic,m8$aic,m9$aic,m10$aic,m11$aic,m12$aic,m13$aic,m14$aic)
d <- data.frame(pq = c("(1,0)","(2,0)","(3,0)","(4,0)","(0,1)","(0,2)","(1,1)","(2,1)","(3,1)","(4,1)","(1,2)","(2,2)","(3,2)","(4,2)"),sigma2,loglik,AIC)
d
# Order this by sigma2
d[order(d$sigma2),]
# Order this by loglik
d[order(-d$loglik),]
# Order this by AIC
d[order(d$AIC),]
names(m1)
m1$coef
length(m1$coef)
length(m5$coef)
length(m11$coef)
ma
m5
m11
D <- -2*(m5$loglik - m11$loglik)
pval <- 1-pchisq(D,3)
print(c("Test Statistic:",D,"P-value:",pval))
pval <- 1-pchisq(D,2)
print(c("Test Statistic:",D,"P-value:",pval))
setwd("~/Documents/Module2/msan604/AP")
library(tseries)
library(forecast)
dat <- read.csv("train.csv")
as.Date.ts(dat$Month)
as.Date.ts(dat$Month, "%m%Y")
as.Date(dat$Month, "%m%Y")
str_sub(dat$Month, start= -4)
substrRight <- function(x, n){
substr(x, nchar(x)-n+1, nchar(x))
}
substrRight(dat$Month, 4)
rep(1:12, 5)
len(dat$Month)
length(dat$Month)
288/12
dat <- read.csv("train.csv")
dat$Year <- substrRight(dat$Month, 4)
dat$Month <- rep(1:12, length(dat$Month)/12)
integer("1987")
as.numeric(dat$Year)
dat$Year <- as.numeric(substrRight(dat$Month, 4))
dat$Month <- rep(1:12, length(dat$Month)/12)
dat <- read.csv("train.csv")
dat$Year <- as.numeric(substrRight(dat$Month, 4))
dat$Month <- rep(1:12, length(dat$Month)/12)
LakeHuron
ts(dat$Unemployment_Rate, c(1987, 1), frequency = 12)
plot(ts(dat$Unemployment_Rate, c(1987, 1), frequency = 12))
dat <- ts(dat$Unemployment_Rate, c(1987, 1), frequency = 12)
par(mfrow=c(2,1))
plot(dat)
acf(dat, lag.max = 72)
dat <- read.csv("train.csv")
dat$Year <- as.numeric(substrRight(dat$Month, 4))
dat$Month <- rep(1:12, length(dat$Month)/12)
dat.ts <- ts(dat$Unemployment_Rate, c(1987, 1), frequency = 12)
par(mfrow=c(2,1))
plot(dat)
acf(dat, lag.max = 72)
dat <- read.csv("train.csv")
dat$Year <- as.numeric(substrRight(dat$Month, 4))
dat$Month <- rep(1:12, length(dat$Month)/12)
dat.ts <- ts(dat$Unemployment_Rate, c(1987, 1), frequency = 12)
par(mfrow=c(2,1))
plot(dat)
par(mfrow=c(2,1))
plot(dat.ts)
acf(dat.ts, lag.max = 72)
adf.test(dat.ts)
dat.ts.1 <- diff(dat.ts)
plot(dat.ts.1)
acf(dat.ts.1)
adf.test(dat.ts.1)
ndiffs(x=dat.ts, test="adf", max.d=10)
auto.arima(dat.ts, allowdrift = F)
plot(dat.ts)
acf(dat.ts, lag.max = 144)
dat.ts.1 <- diff(dat.ts)
plot(dat.ts.1)
acf(dat.ts.1, lag.max = 144)
adf.test(dat.ts.1) #d=1
nsdiffs(dat.ts, m = 12)
acf(dat.ts.1, lag.max = 144)
pacf(dat.ts.1, lag.max = 144)
acf(dat.ts.1, lag.max = 72) # q<=, Q<=2
pacf(dat.ts.1, lag.max = 72) # p<=, P<=3
m0 <- arima(dat.ts, c(5,1,5), list(3,0,2), period=12)
m0 <- arima(dat.ts, c(5,1,5), list(order=c(3,0,2), period=12))
summary(m0)
f<-forecast(m0, h=60, level=0.95)
f <- forecast(m0, h=24, level=0.95)
l <- ts(f$lower, start = c(2011, 1), frequency = 12)  #95% PI LL
h <- ts(f$upper, start = c(2011, 1), frequency = 12) #95% PI UL
pred <- f$mean #predictions
par(mfrow=c(1,1))
plot(dat.ts, xlim=c(1987,2013))
abline(v = 2011, lwd = 2, col = "black")
points(pred, type = "l", col = "blue")
points(l, type = "l", col = "red")
points(h, type = "l", col = "red")
points(f$fitted,type="l", col = "green")
legend("topleft", legend = c("Observed", "Fitted", "Predicted", "95% PI"), lty = 1, col = c("black", "green", "blue", "red"), cex = 1)
test <- dat <- read.csv("test.csv")
test$Year <- as.numeric(substrRight(test$Month, 4))
test$Month <- rep(1:12, length(test$Month)/12)
test.ts <- ts(test$Unemployment_Rate, c(1987, 1), frequency = 12)
test.ts <- ts(test$Unemployment_Rate, c(2011, 1), frequency = 12)
point(test.ts, type="l", col = "black")
points(test.ts, type="l", col = "black")
plot(dat.ts, xlim=c(1987,2013))
abline(v = 2011, lwd = 2, col = "black")
points(pred, type = "l", col = "blue")
points(l, type = "l", col = "red")
points(h, type = "l", col = "red")
points(f$fitted, type="l", col = "green")
points(test.ts, type="l", col = "pink")
legend("topleft", legend = c("Observed", "Fitted", "Predicted", "95% PI", "Actual"), lty = 1, col = c("black", "green", "blue", "red", "pink"), cex = 1)
f <- forecast(m0, h=24, level=0.5)
l <- ts(f$lower, start = c(2011, 1), frequency = 12)  #95% PI LL
h <- ts(f$upper, start = c(2011, 1), frequency = 12) #95% PI UL
pred <- f$mean #predictions
par(mfrow=c(1,1))
plot(dat.ts, xlim=c(1987,2013))
abline(v = 2011, lwd = 2, col = "black")
points(pred, type = "l", col = "blue")
points(l, type = "l", col = "red")
points(h, type = "l", col = "red")
points(f$fitted, type="l", col = "green")
points(test.ts, type="l", col = "pink")
legend("topleft", legend = c("Observed", "Fitted", "Predicted", "95% PI", "Actual"), lty = 1, col = c("black", "green", "blue", "red", "pink"), cex = 1)
f <- forecast(m0, h=24, level=0.95)
l <- ts(f$lower, start = c(2011, 1), frequency = 12)  #95% PI LL
h <- ts(f$upper, start = c(2011, 1), frequency = 12) #95% PI UL
pred <- f$mean #predictions
par(mfrow=c(1,1))
plot(dat.ts, xlim=c(1987,2013))
abline(v = 2011, lwd = 2, col = "black")
points(pred, type = "l", col = "blue")
points(l, type = "l", col = "red")
points(h, type = "l", col = "red")
points(f$fitted, type="l", col = "green")
points(test.ts, type="l", col = "pink")
legend("topleft", legend = c("Observed", "Fitted", "Predicted", "95% PI", "Actual"), lty = 1, col = c("black", "green", "blue", "red", "pink"), cex = 1)
