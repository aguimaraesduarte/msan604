anova1$`Sum Sq`[7]
tail(anova1$"Sum Sq", 1)
anova1$Df
F_stat <- (sum(anova1$"Sum Sq"[1:6])/sum(anova1$Df[1:6])) / (tail(anova1$"Sum Sq", 1)/tail(anova1$Df, 1))
F_lim <- qf(p = 0.975, df1 = 6, df2 = 44)
F_stat
cakes <- alr4::cakes
lm1 <- lm(data=cakes, Y ~ X1 + I(X1^2) + X2 + I(X2^2) + X1*X2)
summary(lm1)
n <- nrow(cakes)
pf <- 6
dff <- n-pf
SSEf <- tail(car::Anova(lm1)$"Sum Sq", 1)
MSEf <- SSEf / dff
SSEf
MSEf
MSR_b5 <- car::Anova(lm1)$"Sum Sq"[5] / 1
Fstar_b5 <- MSR_b5 / MSEf
Flim_b5 <- qf(p=0.975, df1=1 , df2=dff)
F_stat <- (sum(anova1$"Sum Sq"[1:6])/sum(anova1$Df[1:6])) / (tail(anova1$"Sum Sq", 1)/tail(anova1$Df, 1))
rm(list=ls())
cat("\014")
cakes <- alr4::cakes
lm1 <- lm(data=cakes, Y ~ X1 + I(X1^2) + X2 + I(X2^2) + X1*X2)
summary(lm1)
n <- nrow(cakes)
pf <- 6
dff <- n-pf
SSEf <- tail(car::Anova(lm1)$"Sum Sq", 1)
MSEf <- SSEf / dff
# a
MSR_b5 <- car::Anova(lm1)$"Sum Sq"[5] / 1
Fstar_b5 <- MSR_b5 / MSEf
Flim_b5 <- qf(p=0.975, df1=1 , df2=dff)
MSR_b5
Fstar_b5
Flim_b5
dff
MSR_b2 <- car::Anova(lm1)$"Sum Sq"[2] / 1
Fstar_b2 <- MSR_b2 / MSEf
Flim_b2 <- qf(p=0.975, df1=1 , df2=dff)
MSR_b2
Fstar_b2
Flim_b2
lm2 <- lm(data=cakes, Y ~ X2 + I(X2^2))
summary(lm2)
pr <- 3
dfr <- n-pr
SSEr <- tail(car::Anova(lm2)$"Sum Sq", 1)
Fstar_b1b2b5 <- ((SSEr - SSEf)/(dfr-dff)) / (SSEf/dff)
Flim_b1b2b5 <- qf(p=0.975, df1=3 , df2=dff)
SSEr
dfr
n-p-3
n-pf-3
n-(pf-3)
Fstar_b1b2b5 <- ((SSEr - SSEf)/(dfr-dff)) / (SSEf/dff)
Fstar_b1b2b5
Flim_b1b2b5 <- qf(p=0.975, df1=3 , df2=dff)
Flim_b1b2b5
dfr-dff
landrent <- alr4::landrent
rm(list=ls())
cat("\014")
landrent <- alr4::landrent
lm1 <- lm(data=landrent, Y ~ X1 + X2 + X3 + X4)
summary(lm1)
plot(landrent)
plot(landrent$Y~landrent$X2)
summary(lm(landrent$Y~landrent$X2))
plot(landrent$Y~landrent$X1)
plot(landrent$Y~landrent$X3)
plot(landrent$Y~landrent$X4)
plot(landrent$Y~landrent$X3)
plot(landrent$Y~log(landrent$X3))
summary(lm(landrent$Y~log(landrent$X3)))
summary(lm(landrent$Y~landrent$X1+log(landrent$X3)))
summary(lm(landrent$Y~landrent$X1+landrent$X2+log(landrent$X3)))
pairs(landrent)
cor(landrent)
plot(landrent)
pairs(landrent)
summary(lm(data=landrent, Y ~ X1 + X2 + X3))
summary(lm(data=landrent, Y ~ X1 + X2 + X4))
lm_f <- lm(data=landrent, Y ~ X1 + X2)
summary(lm_f)
scatterplot(landrent)
scatterplot(landrent$X1, landrent$Y)
scatterplot(landrent$Y~landrent$X1)
scatterplot(landrent$Y~landrent$X1+landrent$X2)
residualPlot(lm_f)
plot(lm_f$residuals, xlab="Sequence", ylab="Residuals",
main="Sequence Plot")
par(mfrow=c(1,2))
plot(stdres(lm_f), xlab="", ylab="",
main="Standardized Residual Plot")
library(MASS)
detach(MASS)
detach("MASS")
detach("package:MASS", unload=TRUE)
par(mfrow=c(1,2))
plot(MASS::stdres(lm_f), xlab="", ylab="",
main="Standardized Residual Plot")
abline(h=0)
plot(MASS::studres(lm_f), xlab="", ylab="",
main="Studentized Residual Plot")
abline(h=0)
par(mfrow=c(1,1))
residplot <- function(fit, nbreaks=10) {
z <- rstudent(fit)
hist(z, breaks=nbreaks, freq=FALSE,
xlab="Studentized Residual",
main="Distribution of Errors")
rug(jitter(z), col="brown")
curve(dnorm(x, mean=mean(z), sd=sd(z)),
add=TRUE, col="blue", lwd=2)
lines(density(z)$x, density(z)$y,
col="red", lwd=2, lty=2)
legend("topright",
legend = c( "Normal Curve", "Kernel Density Curve"),
lty=1:2, col=c("blue","red"), cex=.7)
}
residplot(lm_f)
shapiro.test(lm_UN$residuals)
shapiro.test(lm_f$residuals)
qqPlot(residuals(lm_f), main="landrent: Normal QQ-Plot", xlab="", ylab="")
residualPlot(lm_f)
plot(lm_f$residuals, xlab="Sequence", ylab="Residuals",
main="Sequence Plot")
par(mfrow=c(1,2))
plot(MASS::stdres(lm_f), xlab="", ylab="",
main="Standardized Residual Plot")
abline(h=0)
plot(MASS::studres(lm_f), xlab="", ylab="",
main="Studentized Residual Plot")
abline(h=0)
plot(landrent)
par(mfrow=c(1,2))
plot(MASS::stdres(lm_f), xlab="Standardized Residual", ylab="Sequence",
main="Standardized Residual Plot")
abline(h=0)
plot(MASS::studres(lm_f), xlab="Studentized Residual", ylab="Sequence",
main="Studentized Residual Plot")
abline(h=0)
par(mfrow=c(1,1))
residplot <- function(fit, nbreaks=10) {
z <- rstudent(fit)
hist(z, breaks=nbreaks, freq=FALSE,
xlab="Studentized Residual",
main="Distribution of Errors")
rug(jitter(z), col="brown")
curve(dnorm(x, mean=mean(z), sd=sd(z)),
add=TRUE, col="blue", lwd=2)
lines(density(z)$x, density(z)$y,
col="red", lwd=2, lty=2)
legend("topright",
legend = c( "Normal Curve", "Kernel Density Curve"),
lty=1:2, col=c("blue","red"), cex=.7)
}
residplot(lm_f)
plot(lm_f$residuals, xlab="Sequence", ylab="Residuals",
main="Sequence Plot")
par(mfrow=c(1,2))
plot(MASS::stdres(lm_f), xlab="Standardized Residual", ylab="Sequence",
main="Standardized Residual Plot")
abline(h=0)
plot(MASS::studres(lm_f), xlab="Studentized Residual", ylab="Sequence",
main="Studentized Residual Plot")
abline(h=0)
par(mfrow=c(1,2))
plot(MASS::stdres(lm_f), xlab="Sequence", ylab="Standardized Residual",
main="Standardized Residual Plot")
abline(h=0)
plot(MASS::studres(lm_f), xlab="Sequence", ylab="Studentized Residual",
main="Studentized Residual Plot")
abline(h=0)
landrent
bptest(lm_f)
lm_test::bptest(lm_f)
lmtest::bptest(lm_f)
residualPlot(lm_f)
par(mfrow=c(1,1))
residualPlot(lm_f)
landrent$X1
median(landrent$X1)
median(landrent$X2)
landrent
landrent$Group <- factor(apply(landrent, 1, function(x){
if(x[1]<=44.56){return(0)} else{return(1)}}))
landrent
leveneTest(data=landrent, Y ~ Group, center=median)
lm3 <- lm(data=landrent, Y ~ X1 + X2 + X3)
summary(lm3)
lm4 <- lm(data=landrent, Y ~ X1 + X2 + X4)
summary(lm3)
summary(lm_f)
qqPlot(residuals(lm_f), main="landrent: Normal QQ-Plot", xlab="", ylab="")
residplot(lm_f)
leveneTest(data=landrent, Y ~ Group, center=median)
shapiro.test(lm_f$residuals)
lm3 <- lm(data=landrent, Y ~ X1 + X2 + X3)
summary(lm3)
summary(lm_f)
summary(lm3)
lm4 <- lm(data=landrent, Y ~ X1 + X2 + X4)
summary(lm3)
summary(lm34
)
summary(lm4)
summary(lm1)
summary(lm(data=landrent, Y ~ X1 + X3)
)
rm(list=ls())
cat("\014")
rateprof <- alr4::Rateprof
detach("package:car", unload=TRUE)
transaction <- Transact
transaction <- alr4::Transact
normal <- rnorm(5000, 0, 1) + c(1, 0, 2, 0, 1)
plot(normal)
shapiro.test(normal)
normal <- rnorm(5000, 0, 1) + c(1, 0, 2, 0, 1)
shapiro.test(normal)
non_normal <- runif(10)
non_normal
dist(non_normal)
hist(non_normal)
shapiro.test(non_normal)
non_normal <- runif(10)
shapiro.test(non_normal)
hist(non_normal)
non_normal <- replicate(1000, shapiro.test(runif(10))$p.value)
rowMeans(non_normal<0.05)
non_normal<0.05
sum(non_normal<0.05)
sum(non_normal<0.05)/1000
non_normal <- replicate(5000, shapiro.test(runif(10))$p.value)
sum(non_normal<0.05)/1000
sum(non_normal<0.05)/5000
non_normal <- replicate(5000, shapiro.test(runif(10))$p.value)
sum(non_normal<0.05)/length(non_normal)
normal <- rnorm(5000, 0, 1) + runif(5000, 1, 2)
normal <- replicate(rnorm(5000, 0, 1))# + runif(5000, 1, 2)
normal <- replicate(5000, rnorm(5000, 0, 1))# + runif(5000, 1, 2)
normal <- replicate(5000, shapiro.test(rnorm(5000, 0, 1))$p.value)# + runif(5000, 1, 2)
sum(normal<0.05)/length(normal)
sum(non_normal<0.05)/length(non_normal) * 100
sum(normal<0.05)/length(normal) * 100
sum(non_normal>0.05)/length(non_normal) * 100 # percent of times non-normal data is considered normal
sum(normal<0.05)/length(normal) * 100 # percent of times normal data is considered non-normal
install.packages("leaps")
install.packages("xlsx")
install.packages("rJava")
install.packages("xlsx")
library(xlsx)
library(rJava)
install.packages("rJava")
library(xlsx)
library(rJava)
Sys.getenv("JAVA_HOME")
install.packages("QuantPsyc")
install.packages('lawstat')
library(lawstat) # levene.test and runs.test need this
par(mfrow=c(2,1))
plot(BJsales)
BJ2 <- diff(diff(BJsales))
plot(BJ2)
# Fit the ARMA(1,2) model and extract the residuals
m <- arima(BJ2, order = c(1,0,2))
e <- m$residuals # residuals
r <- e/sqrt(m$sigma2) # standardized residuals
par(mfrow=c(2,1))
plot(e, main="Residuals vs t", ylab="")
abline(h=0, col="red")
plot(r, main="Standardized Residuals vs t", ylab="")
abline(h=0, col="red")
# test whether residuals have zero mean
t.test(e)
# test for heteroscedasticity
par(mfrow=c(1,1))
plot(e, main="Residuals vs t", ylab="")
abline(v=c(37,74,111), lwd=3, col="red")
group <- c(rep(1,37),rep(2,37),rep(3,37),rep(4,37))
levene.test(e,group) #Levene
bartlett.test(e,group) #Bartlett
# test for uncorrelatedness / randomness
tsdiag(m) #ACF and Ljung-Box test all in one!
runs.test(e) #Runs test for randomness
# test for normality
par(mfrow=c(1,1))
qqnorm(e, main="QQ-plot of Residuals")
qqline(e)
shapiro.test(e) #SW test
#######################
## ACF-PACF Examples ##
#######################
# MA(1) with n = 200
par(mfcol=c(3,1))
data.sim <- arima.sim(n = 200, list(ma = c(0.7)), sd = sqrt(1))
plot(data.sim, main="Simulated Data from an MA(1) Process")
acf(data.sim, main = "")
pacf(data.sim, main = "")
# or: acf(data.sim, type="partial")
# MA(1) with n = 1000
par(mfcol=c(3,1))
data.sim <- arima.sim(n = 1000, list(ma = c(0.7)), sd = sqrt(1))
plot(data.sim, main="Simulated Data from an MA(1) Process")
acf(data.sim, main = "")
pacf(data.sim, main = "")
# MA(2) with n = 200
par(mfcol=c(3,1))
data.sim <- arima.sim(n = 200, list(ma = c(0.7,-1)), sd = sqrt(1))
plot(data.sim, main="Simulated Data from an MA(2) Process")
acf(data.sim, main = "")
pacf(data.sim, main = "")
# MA(3) with n = 200
par(mfcol=c(3,1))
data.sim <- arima.sim(n = 200, list(ma = c(1,1,1)), sd = sqrt(1))
plot(data.sim, main="Simulated Data from an MA(3) Process")
acf(data.sim, main = "")
pacf(data.sim, main = "")
# AR(1) with n = 200
par(mfcol=c(3,1))
data.sim <- arima.sim(n = 200, list(ar = c(0.7)), sd = sqrt(1))
plot(data.sim, main="Simulated Data from an AR(1) Process")
acf(data.sim, main = "")
pacf(data.sim, main = "")
# AR(1) with n = 1000
par(mfcol=c(3,1))
data.sim <- arima.sim(n = 1000, list(ar = c(0.7)), sd = sqrt(1))
plot(data.sim, main="Simulated Data from an AR(1) Process")
acf(data.sim, main = "")
pacf(data.sim, main = "")
# AR(2) with n = 200
par(mfcol=c(3,1))
data.sim <- arima.sim(n =200, list(ar = c(-0.7, 0.1)), sd = sqrt(1))
plot(data.sim, main="Simulated Data from an AR(2) Process")
acf(data.sim, main = "")
pacf(data.sim, main = "")
# AR(4) with n = 200
par(mfcol=c(3,1))
data.sim <- arima.sim(n = 200, list(ar = c(0.7, 0.1, -0.2, 0.1)), sd = sqrt(1))
plot(data.sim, main="Simulated Data from an AR(4) Process")
acf(data.sim, main = "")
pacf(data.sim, main = "")
# ARMA(1,1) with n = 200
par(mfcol=c(3,1))
data.sim <- arima.sim(n = 200, list(ar=c(0.5) , ma = c(1)), sd = sqrt(1))
plot(data.sim, main="Simulated Data from an ARMA(1,1) Process")
acf(data.sim, main = "")
pacf(data.sim, main = "")
# ARMA(2,1) with n = 200
par(mfcol=c(3,1))
data.sim <- arima.sim(n = 200, list(ar=c(0.3,0.65) , ma = c(-0.5)), sd = sqrt(1))
plot(data.sim, main="Simulated Data from an ARMA(2,1) Process")
acf(data.sim, main = "")
pacf(data.sim, main = "")
#ARMA Fitting Example
#Use the BJsales data. Note that we have to assume the underlying time series is stationary,
#which this clearly not (check this:)
par(mfrow=c(2,1))
plot(BJsales)
#Instead we'll use the twice-differenced version of this time series. More discussion of the
#idea behind this differencing to come.
BJ2 <- diff(diff(BJsales))
plot(BJ2)
#Step 1 in the Box-Jenkins process is "Identification" (i.e., order identification).
#We will use ACF and PACF plots to help us decide what p and q are
acf(BJ2)
pacf(BJ2)
acf(BJ2, type="partial")
pacf(BJ2)
acf(BJ2)
pacf(BJ2)
fit.ar <- arima(BJ2, order=c(3,0,0)) #AR(3)
fit.ar
fit.ma <- arima(BJ2, order=c(0,0,1)) #MA(1)
fit.ma
fit.arma <- arima(BJ2, order=c(3,0,1)) #ARMA(3,1)
fit.arma
anova(fit.ma, fit.arma)
fitls.ar <- arima(BJ2, order=c(3,0,0), method="CSS") #AR(3)
fitls.ar
fitls.ma <- arima(BJ2, order=c(0,0,1), method="CSS") #MA(1)
fitls.ma
fitls.arma <- arima(BJ2, order=c(3,0,1), method="CSS") #ARMA(3,1)
fitls.arma
#We can fit any number of models of different orders and use the output information to select
#the model with the best fit.
m1<-arima(BJ2,order=c(1,0,0))
m2<-arima(BJ2,order=c(2,0,0))
m3<-arima(BJ2,order=c(3,0,0))
m4<-arima(BJ2,order=c(4,0,0))
m5<-arima(BJ2,order=c(0,0,1))
m6<-arima(BJ2,order=c(0,0,2))
m7<-arima(BJ2,order=c(1,0,1))
m8<-arima(BJ2,order=c(2,0,1))
m9<-arima(BJ2,order=c(3,0,1))
m10<-arima(BJ2,order=c(4,0,1))
m11<-arima(BJ2,order=c(1,0,2))
m12<-arima(BJ2,order=c(2,0,2))
m13<-arima(BJ2,order=c(3,0,2))
m14<-arima(BJ2,order=c(4,0,2))
sigma2<-c(m1$sigma2,m2$sigma2,m3$sigma2,m4$sigma2,m5$sigma2,m6$sigma2,m7$sigma2,m8$sigma2,m9$sigma2,m10$sigma2,m11$sigma2,m12$sigma2,m13$sigma2,m14$sigma2)
loglik<-c(m1$loglik,m2$loglik,m3$loglik,m4$loglik,m5$loglik,m6$loglik,m7$loglik,m8$loglik,m9$loglik,m10$loglik,m11$loglik,m12$loglik,m13$loglik,m14$loglik)
AIC<-c(m1$aic,m2$aic,m3$aic,m4$aic,m5$aic,m6$aic,m7$aic,m8$aic,m9$aic,m10$aic,m11$aic,m12$aic,m13$aic,m14$aic)
d <- data.frame(pq = c("(1,0)","(2,0)","(3,0)","(4,0)","(0,1)","(0,2)","(1,1)","(2,1)","(3,1)","(4,1)","(1,2)","(2,2)","(3,2)","(4,2)"),sigma2,loglik,AIC)
d
# Order this by sigma2
d[order(d$sigma2),]
# Order this by loglik
d[order(-d$loglik),]
# Order this by AIC
d[order(d$AIC),]
names(m1)
m1$coef
length(m1$coef)
length(m5$coef)
length(m11$coef)
ma
m5
m11
D <- -2*(m5$loglik - m11$loglik)
pval <- 1-pchisq(D,3)
print(c("Test Statistic:",D,"P-value:",pval))
pval <- 1-pchisq(D,2)
print(c("Test Statistic:",D,"P-value:",pval))
setwd("~/Documents/Module2/msan604/A3")
# Reset R session
rm(list=ls())
cat("\014")
# Load libraries
library(tseries)
library(forecast)
library(lawstat)
library(vars)
#######################################
##### IMPORT DATA, VISUALIZE
#######################################
china <- read.csv("china.csv")
ch.exp <- ts(china$ch.exp, start = c(1984,1), frequency = 12)
ch.imp <- ts(china$ch.imp, start = c(1984,1), frequency = 12)
# train and test files (80/20)
ch.exp.train <- ts(ch.exp[time(ch.exp) < 2003], start = c(1984,1), frequency = 12)
ch.exp.test <- ts(ch.exp[time(ch.exp) >= 2003], start = c(2003,1), frequency = 12)
ch.imp.train <- ts(ch.imp[time(ch.imp) < 2003], start = c(1984,1), frequency = 12)
ch.imp.test <- ts(ch.imp[time(ch.imp) >= 2003], start = c(2003,1), frequency = 12)
plot(ch.exp.train, main = "Monthly Exports in China", ylab = "Exports (Million USD)",
xlab = "Time") # trend + seasonality -> log-transform
plot(log(ch.exp.train), main = "Log-Monthly Exports in China",
ylab = "Log-Exports (Million USD)", xlab = "Time")
plot(ch.exp, main = "Monthly Exports in China", ylab = "Exports (Million USD)",
xlab = "Time")
abline(v=2003, col="red")
plot(ch.imp, main = "Monthly Imports in China", ylab = "Exports (Million USD)",
xlab = "Time")
abline(v=2003, col="red")
l.ch.exp <- log(ch.exp)
l.ch.imp <- log(ch.imp)
l.ch.exp.train <- log(ch.exp.train)
l.ch.exp.test <- log(ch.exp.test)
l.ch.imp.train <- log(ch.imp.train)
l.ch.imp.test <- log(ch.imp.test)
plot(l.ch.exp, main = "Log-Monthly Exports in China",
ylab = "Log-Exports (Million USD)", xlab = "Time")
abline(v=2003, col="red")
plot(l.ch.imp, main = "Log-Monthly Imports in China",
ylab = "Log-Exports (Million USD)", xlab = "Time")
abline(v=2003, col="red")
#######################################
VARselect(y = data.frame(l.ch.exp.train, l.ch.imp.train)) #p=3
# For the sake of parsimony let's choose p=2
m.var <- VAR(y = data.frame(l.ch.exp.train, l.ch.imp.train), p = 3, season = 12,
type = "trend")
plot(m.var)
# Let's now do some forecasting with this model
pred <- predict(m.var, n.ahead = 72, ci = 0.95)
plot(pred)
# Forecasting
f <- ts(pred$fcst$l.ch.exp.train[,1], start = c(2003, 1), frequency = 12)
l <- ts(pred$fcst$l.ch.exp.train[,2], start = c(2003, 1), frequency = 12)  #95% PI LL
h <- ts(pred$fcst$l.ch.exp.train[,3], start = c(2003, 1), frequency = 12) #95% PI UL
pred_ <- ts(m.var$varresult$l.ch.exp.train$fitted.values, start = c(1984,1), frequency = 12)
par(mfrow=c(1,1))
plot(ch.exp.train, xlim=c(1984,2009), ylim=c(0,1500), main = "Monthly Exports in China",
ylab = "Exports (Million USD)", xlab = "Time")
abline(v = 2003, lwd = 1, col = "black")
points(exp(pred_), type = "l", col = "blue")
points(exp(l), type = "l", col = "red")
points(exp(h), type = "l", col = "red")
points(exp(f), type="l", col = "green")
points(ch.exp.test, type = "l", col = "orange")
legend("topleft", legend = c("Observed", "Fitted", "Predicted", "95% PI", "Actual"),
lty = 1, col = c("black", "green", "blue", "red", "orange"), cex = 1)
# Test RMSE
pred.var <- pred$fcst$l.ch.exp.train[,1]
rmse.var <- sqrt(mean((ch.exp.test - exp(pred.var))^2))
rmse.var
plot(ch.exp.train, xlim=c(1984,2009), ylim=c(0,1500), main = "Monthly Exports in China",
ylab = "Exports (Million USD)", xlab = "Time")
abline(v = 2003, lwd = 1, col = "black")
points(exp(f), type = "l", col = "blue")
points(exp(l), type = "l", col = "red")
points(exp(h), type = "l", col = "red")
points(exp(pred_), type="l", col = "green")
points(ch.exp.test, type = "l", col = "orange")
legend("topleft", legend = c("Observed", "Fitted", "Predicted", "95% PI", "Actual"),
lty = 1, col = c("black", "green", "blue", "red", "orange"), cex = 1)
pred_
f
exp(f)
exp(pred_)
